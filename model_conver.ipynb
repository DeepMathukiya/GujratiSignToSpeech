{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE From"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow consists of the following steps:\n",
    "\n",
    "1.Convert the TensorFlow/Keras model to a .pb file.\n",
    "2.Convert the .pb file to the ONNX format.\n",
    "3.Create a TensorRT engine. \n",
    "4.Run inference from the TensorRT engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras2onnx\n",
      "  Downloading keras2onnx-1.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tf2onnx in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (1.16.1)\n",
      "Collecting pycuda\n",
      "  Downloading pycuda-2025.1.1.tar.gz (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "     ------------ --------------------------- 0.5/1.7 MB 134.2 kB/s eta 0:00:09\n",
      "     ------------ --------------------------- 0.5/1.7 MB 134.2 kB/s eta 0:00:09\n",
      "     ------------ --------------------------- 0.5/1.7 MB 134.2 kB/s eta 0:00:09\n",
      "     ------------ --------------------------- 0.5/1.7 MB 134.2 kB/s eta 0:00:09\n",
      "     ------------ --------------------------- 0.5/1.7 MB 134.2 kB/s eta 0:00:09\n",
      "     ------------ --------------------------- 0.5/1.7 MB 134.2 kB/s eta 0:00:09\n",
      "     ------------------ --------------------- 0.8/1.7 MB 159.0 kB/s eta 0:00:06\n",
      "     ------------------ --------------------- 0.8/1.7 MB 159.0 kB/s eta 0:00:06\n",
      "     ------------------ --------------------- 0.8/1.7 MB 159.0 kB/s eta 0:00:06\n",
      "     ------------------------ --------------- 1.0/1.7 MB 206.2 kB/s eta 0:00:04\n",
      "     ------------------------ --------------- 1.0/1.7 MB 206.2 kB/s eta 0:00:04\n",
      "     ------------------------ --------------- 1.0/1.7 MB 206.2 kB/s eta 0:00:04\n",
      "     ------------------------ --------------- 1.0/1.7 MB 206.2 kB/s eta 0:00:04\n",
      "     ------------------------ --------------- 1.0/1.7 MB 206.2 kB/s eta 0:00:04\n",
      "     ------------------------------- -------- 1.3/1.7 MB 216.5 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 1.3/1.7 MB 216.5 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 1.3/1.7 MB 216.5 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 1.3/1.7 MB 216.5 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 1.3/1.7 MB 216.5 kB/s eta 0:00:02\n",
      "     ------------------------------------- -- 1.6/1.7 MB 223.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 229.0 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from keras2onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from keras2onnx) (4.25.8)\n",
      "Requirement already satisfied: requests in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from keras2onnx) (2.32.3)\n",
      "Requirement already satisfied: onnx in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from keras2onnx) (1.16.2)\n",
      "Collecting onnxconverter-common>=1.7.0 (from keras2onnx)\n",
      "  Downloading onnxconverter_common-1.15.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fire (from keras2onnx)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: six in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from tf2onnx) (24.3.25)\n",
      "Collecting protobuf (from keras2onnx)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting pytools>=2011.2 (from pycuda)\n",
      "  Downloading pytools-2025.2.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from pycuda) (4.2.0)\n",
      "Collecting mako (from pycuda)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from onnxconverter-common>=1.7.0->keras2onnx) (24.0)\n",
      "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
      "  Downloading siphash24-1.7-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from pytools>=2011.2->pycuda) (4.11.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from fire->keras2onnx) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from mako->pycuda) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras2onnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras2onnx) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras2onnx) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dsmat\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras2onnx) (2024.2.2)\n",
      "Downloading keras2onnx-1.7.0-py3-none-any.whl (96 kB)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Downloading onnxconverter_common-1.15.0-py2.py3-none-any.whl (89 kB)\n",
      "Downloading pytools-2025.2.2-py3-none-any.whl (98 kB)\n",
      "Downloading siphash24-1.7-cp311-cp311-win_amd64.whl (80 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: pycuda\n",
      "  Building wheel for pycuda (pyproject.toml): started\n",
      "  Building wheel for pycuda (pyproject.toml): finished with status 'error'\n",
      "Failed to build pycuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pycuda (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [155 lines of output]\n",
      "      *************************************************************\n",
      "      *** I have detected that you have not run configure.py.\n",
      "      *************************************************************\n",
      "      *** Additionally, no global config files were found.\n",
      "      *** I will go ahead with the default configuration.\n",
      "      *** In all likelihood, this will not work out.\n",
      "      ***\n",
      "      *** See README_SETUP.txt for more information.\n",
      "      ***\n",
      "      *** If the build does fail, just re-run configure.py with the\n",
      "      *** correct arguments, and then retry. Good luck!\n",
      "      *************************************************************\n",
      "      *** HIT Ctrl-C NOW IF THIS IS NOT WHAT YOU WANT\n",
      "      *************************************************************\n",
      "      Continuing in 10 seconds...\n",
      "      Continuing in 9 seconds...\n",
      "      Continuing in 8 seconds...\n",
      "      Continuing in 7 seconds...\n",
      "      Continuing in 6 seconds...\n",
      "      Continuing in 5 seconds...\n",
      "      Continuing in 4 seconds...\n",
      "      Continuing in 3 seconds...\n",
      "      Continuing in 2 seconds...\n",
      "      Continuing in 1 seconds...\n",
      "      \n",
      "      C:\\Users\\dsmat\\AppData\\Local\\Temp\\pip-build-env-3p_6r769\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:289: UserWarning: Unknown distribution option: 'test_requires'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\dsmat\\AppData\\Local\\Temp\\pip-build-env-3p_6r769\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: MIT License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\autoinit.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\autoprimaryctx.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\characterize.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\compiler.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\cumath.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\curandom.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\debug.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\driver.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\elementwise.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\gpuarray.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\reduction.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\scan.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\tools.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\_cluda.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\_mymako.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      copying pycuda\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "      creating build\\lib.win-amd64-cpython-311\\pycuda\\gl\n",
      "      copying pycuda\\gl\\autoinit.py -> build\\lib.win-amd64-cpython-311\\pycuda\\gl\n",
      "      copying pycuda\\gl\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\\gl\n",
      "      creating build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      copying pycuda\\sparse\\cg.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      copying pycuda\\sparse\\coordinate.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      copying pycuda\\sparse\\inner.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      copying pycuda\\sparse\\operator.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      copying pycuda\\sparse\\packeted.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      copying pycuda\\sparse\\pkt_build.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      copying pycuda\\sparse\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      creating build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "      copying pycuda\\compyte\\array.py -> build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "      copying pycuda\\compyte\\dtypes.py -> build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "      copying pycuda\\compyte\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "      running egg_info\n",
      "      writing pycuda.egg-info\\PKG-INFO\n",
      "      writing dependency_links to pycuda.egg-info\\dependency_links.txt\n",
      "      writing requirements to pycuda.egg-info\\requires.txt\n",
      "      writing top-level names to pycuda.egg-info\\top_level.txt\n",
      "      reading manifest file 'pycuda.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no files found matching 'doc\\source\\*.rst'\n",
      "      warning: no files found matching 'doc\\source\\conf.py'\n",
      "      warning: no files found matching 'doc\\source\\_static\\*.css'\n",
      "      warning: no files found matching 'doc\\source\\_templates\\*.html'\n",
      "      warning: no files found matching '*.cpp' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "      warning: no files found matching '*.html' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "      warning: no files found matching '*.inl' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "      warning: no files found matching '*.txt' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "      warning: no files found matching '*.h' under directory 'bpl-subset\\bpl_subset\\libs'\n",
      "      warning: no files found matching '*.ipp' under directory 'bpl-subset\\bpl_subset\\libs'\n",
      "      warning: no files found matching '*.pl' under directory 'bpl-subset\\bpl_subset\\libs'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'pycuda.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\dsmat\\AppData\\Local\\Temp\\pip-build-env-3p_6r769\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'pycuda.cuda' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'pycuda.cuda' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'pycuda.cuda' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'pycuda.cuda' to be distributed and are\n",
      "              already explicitly excluding 'pycuda.cuda' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      creating build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "      copying pycuda\\cuda\\pycuda-complex-impl.hpp -> build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "      copying pycuda\\cuda\\pycuda-complex.hpp -> build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "      copying pycuda\\cuda\\pycuda-helpers.hpp -> build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "      copying pycuda\\sparse\\pkt_build_cython.pyx -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "      running build_ext\n",
      "      building '_driver' extension\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\bpl-subset\\bpl_subset\\libs\\python\\src\\converter\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\bpl-subset\\bpl_subset\\libs\\python\\src\\object\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\bpl-subset\\bpl_subset\\libs\\smart_ptr\\src\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\bpl-subset\\bpl_subset\\libs\\system\\src\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\bpl-subset\\bpl_subset\\libs\\thread\\src\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\bpl-subset\\bpl_subset\\libs\\thread\\src\\win32\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\\cpp\n",
      "      creating build\\temp.win-amd64-cpython-311\\Release\\src\\wrapper\n",
      "      \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.44.35207\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -DBOOST_ALL_NO_LIB=1 -DBOOST_THREAD_BUILD_DLL=1 -DBOOST_MULTI_INDEX_DISABLE_SERIALIZATION=1 -DBOOST_PYTHON_SOURCE=1 -Dboost=pycudaboost -DBOOST_THREAD_DONT_USE_CHRONO=1 -DPYGPU_PACKAGE=pycuda -DPYGPU_PYCUDA=1 -DHAVE_CURAND=1 -Isrc/cpp -Ibpl-subset/bpl_subset \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\\include\" -IC:\\Users\\dsmat\\AppData\\Local\\Temp\\pip-build-env-3p_6r769\\overlay\\Lib\\site-packages\\numpy\\_core\\include \"-IC:\\Program Files\\Python311\\include\" \"-IC:\\Program Files\\Python311\\Include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.44.35207\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" /EHsc /Tpbpl-subset/bpl_subset/libs/python/src/converter/arg_to_python_base.cpp /Fobuild\\temp.win-amd64-cpython-311\\Release\\bpl-subset\\bpl_subset\\libs\\python\\src\\converter\\arg_to_python_base.obj /EHsc\n",
      "      arg_to_python_base.cpp\n",
      "      C:\\Program Files\\Python311\\include\\pyconfig.h(59): fatal error C1083: Cannot open include file: 'io.h': No such file or directory\n",
      "      error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.44.35207\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pycuda\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (pycuda)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras2onnx tf2onnx pycuda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the model to .pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in .keras format: models/newdata_model.keras\n",
      "=== Model Conversion ===\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in .keras format: models/newdata_model.keras\n",
      "=== Model Conversion ===\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in .keras format: models/newdata_model.keras\n",
      "=== Model Conversion ===\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as SavedModel: models/newdata_savedmodel\n",
      "Starting ONNX conversion...\n",
      "Trying direct conversion from Keras model...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in .keras format: models/newdata_model.keras\n",
      "=== Model Conversion ===\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as SavedModel: models/newdata_savedmodel\n",
      "Starting ONNX conversion...\n",
      "Trying direct conversion from Keras model...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in .keras format: models/newdata_model.keras\n",
      "=== Model Conversion ===\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as SavedModel: models/newdata_savedmodel\n",
      "Starting ONNX conversion...\n",
      "Trying direct conversion from Keras model...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel conversion failed: module 'tf2onnx.convert' has no attribute 'from_saved_model'\n",
      "\n",
      "Model input shape: (None, 224, 224, 3)\n",
      "Model output shape: (None, 33)\n",
      "❌ ONNX conversion failed - will try command line method in next cell\n",
      "\n",
      "Model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in .keras format: models/newdata_model.keras\n",
      "=== Model Conversion ===\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/newdata_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as SavedModel: models/newdata_savedmodel\n",
      "Starting ONNX conversion...\n",
      "Trying direct conversion from Keras model...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "Direct conversion failed: 'ConcreteFunction' object has no attribute 'get_concrete_function'\n",
      "Trying conversion via SavedModel...\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n",
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel conversion failed: module 'tf2onnx.convert' has no attribute 'from_saved_model'\n",
      "\n",
      "Model input shape: (None, 224, 224, 3)\n",
      "Model output shape: (None, 33)\n",
      "❌ ONNX conversion failed - will try command line method in next cell\n",
      "\n",
      "Model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">102,764,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,201</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │   \u001b[38;5;34m102,764,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │       \u001b[38;5;34m135,201\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,705,443</span> (532.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,705,443\u001b[0m (532.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,681,057</span> (456.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m119,681,057\u001b[0m (456.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Load your model\n",
    "model = tf.keras.models.load_model(\"newdata.h5\")\n",
    "\n",
    "# Method 1: Save in modern Keras format (.keras)\n",
    "model.save(\"models/newdata_model.keras\")\n",
    "print(\"Model saved in .keras format: models/newdata_model.keras\")\n",
    "\n",
    "# Method 2: Convert to ONNX directly from the loaded model\n",
    "def convert_keras_to_onnx(model, output_path):\n",
    "    \"\"\"\n",
    "    Convert Keras model to ONNX format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import tf2onnx\n",
    "        \n",
    "        # Convert model to ONNX\n",
    "        spec = (tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name=\"input\"),)\n",
    "        output_path_onnx = f\"{output_path}.onnx\"\n",
    "        \n",
    "        model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "        tf2onnx.utils.save_protobuf(output_path_onnx, model_proto)\n",
    "        \n",
    "        print(f\"Model converted to ONNX: {output_path_onnx}\")\n",
    "        return output_path_onnx\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"tf2onnx not installed. Install it with: pip install tf2onnx\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to ONNX: {e}\")\n",
    "        return None\n",
    "\n",
    "# Method 3: Save as SavedModel (TensorFlow format)\n",
    "def save_as_savedmodel(model, output_path):\n",
    "    \"\"\"\n",
    "    Save model in SavedModel format\n",
    "    \"\"\"\n",
    "    # For Keras 3, we don't use save_format parameter\n",
    "    # Instead, we use tf.saved_model.save for explicit SavedModel format\n",
    "    tf.saved_model.save(model, output_path)\n",
    "    print(f\"Model saved as SavedModel: {output_path}\")\n",
    "\n",
    "# Execute the conversions\n",
    "print(\"=== Model Conversion ===\")\n",
    "\n",
    "# Save in SavedModel format\n",
    "save_as_savedmodel(model, \"models/newdata_savedmodel\")\n",
    "\n",
    "# Convert to ONNX\n",
    "onnx_path = convert_keras_to_onnx(model, \"models/newdata\")\n",
    "\n",
    "# Print model info\n",
    "print(f\"\\nModel input shape: {model.input_shape}\")\n",
    "print(f\"Model output shape: {model.output_shape}\")\n",
    "print(f\"Model summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the .pb file to ONNX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to convert the .pb model to the ONNX format. To do this, first install tf2onnx. \n",
    "\n",
    "After installing tf2onnx, there are two ways of converting the model from a .pb file to the ONNX format. The first way is to use the command line and the second method is by using Python API. Run the following command:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf2onnx\\convert.py\", line 714, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf2onnx\\convert.py\", line 248, in main\n",
      "    graph_def, inputs, outputs = tf_loader.from_keras(\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf2onnx\\tf_loader.py\", line 668, in from_keras\n",
      "    _keras.backend.set_learning_phase(False)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'keras._tf_keras.keras.backend' has no attribute 'set_learning_phase'\n"
     ]
    }
   ],
   "source": [
    "# Convert to ONNX using command line (more reliable)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def convert_to_onnx_cli(input_path, output_path, method=\"savedmodel\"):\n",
    "    \"\"\"\n",
    "    Convert model to ONNX using tf2onnx command line interface\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method == \"savedmodel\":\n",
    "            # Convert from SavedModel\n",
    "            cmd = [\n",
    "                sys.executable, \"-m\", \"tf2onnx.convert\",\n",
    "                \"--saved-model\", input_path,\n",
    "                \"--output\", output_path,\n",
    "                \"--opset\", \"13\"\n",
    "            ]\n",
    "        elif method == \"keras\":\n",
    "            # Convert from .h5/.keras file\n",
    "            cmd = [\n",
    "                sys.executable, \"-m\", \"tf2onnx.convert\",\n",
    "                \"--keras\", input_path,\n",
    "                \"--output\", output_path,\n",
    "                \"--opset\", \"13\"\n",
    "            ]\n",
    "        \n",
    "        print(f\"Running command: {' '.join(cmd)}\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"✅ Successfully converted to ONNX: {output_path}\")\n",
    "            if result.stdout:\n",
    "                print(\"Output:\", result.stdout)\n",
    "        else:\n",
    "            print(f\"❌ Error converting to ONNX:\")\n",
    "            print(\"STDERR:\", result.stderr)\n",
    "            print(\"STDOUT:\", result.stdout)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Exception during conversion: {e}\")\n",
    "\n",
    "# Try multiple methods\n",
    "print(\"=== Converting to ONNX ===\")\n",
    "\n",
    "# Method 1: From SavedModel\n",
    "convert_to_onnx_cli(\"models/newdata_savedmodel\", \"models/newdata_from_savedmodel.onnx\", \"savedmodel\")\n",
    "\n",
    "# Method 2: From original H5 file\n",
    "convert_to_onnx_cli(\"newdata.h5\", \"models/newdata_from_h5.onnx\", \"keras\")\n",
    "\n",
    "# Method 3: From new Keras file\n",
    "convert_to_onnx_cli(\"models/newdata_model.keras\", \"models/newdata_from_keras.onnx\", \"keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the TensorRT engine from ONNX\n",
    "To create the TensorRT engine from the ONNX file, run the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "def build_engine(onnx_path, shape = [1,224,224,3]):\n",
    "\n",
    "   \"\"\"\n",
    "   This is the function to create the TensorRT engine\n",
    "   Args:\n",
    "      onnx_path : Path to onnx_file. \n",
    "      shape : Shape of the input of the ONNX file. \n",
    "  \"\"\"\n",
    "   with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "       config.max_workspace_size = (256 << 20)\n",
    "       with open(onnx_path, 'rb') as model:\n",
    "           parser.parse(model.read())\n",
    "       network.get_input(0).shape = shape\n",
    "       engine = builder.build_engine(network, config)\n",
    "       return engine\n",
    "\n",
    "def save_engine(engine, file_name):\n",
    "   buf = engine.serialize()\n",
    "   with open(file_name, 'wb') as f:\n",
    "       f.write(buf)\n",
    "def load_engine(trt_runtime, plan_path):\n",
    "   with open(plan_path, 'rb') as f:\n",
    "       engine_data = f.read()\n",
    "   engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "   return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Colab-TF20-TF-TRT-inference-from-Keras-saved-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
